Skip to main content
skills home
Home
Browse
Search
Searchâ€¦
Paths
Channels
Bookmarks
notifications

Pluralsight products
View profile and more
D
SOLID Principles for C# Developers
by Steve Smith

Every C# developer, or any developer using an object-oriented programming language, needs a good understanding of the SOLID principles. These principles guide your design toward more loosely coupled and maintainable software.

Resume Course

Bookmark
Add to Channel
Download Course
Table of contents
Description
Transcript
Exercise files
Discussion
Learning Check
Related Courses
Course Overview
Course Overview
Hi everyone. My name is Steve Smith, aka Ardalis. Welcome to my course, SOLID Principles for C# Developers. This is my 11th Pluralsight course, an update to my most popular course on the SOLID principles of object-oriented design. I'm an independent trainer and mentor for teams and individuals seeking to build better software. You can find me online at ardalis.com and check out my podcast weeklydevtips.com. This course covers the SOLID principles for C# developers, which are principles all professional C# developers should understand and be able to apply. During this course, we'll cover defining the five principles, understanding what responsibilities and dependencies are in our software, understanding how to identify violations of the principles, and when and how to correct violations once you've identified them. By the end of this course, you'll be familiar with five fundamental principles of object-oriented programming and how to apply them to C# applications. Before beginning this course, you should be familiar with C#, but you don't need extensive experience. From here, you should feel comfortable diving into other code quality courses on refactoring, domain-driven design fundamentals, and design patterns. I hope you'll join me on this journey to learn how to apply the five SOLID principles to your C# applications here, on Pluralsight.

Single Responsibility Principle
Introducing SOLID
Hi there. I'm Steve Smith, aka Ardalis. Welcome to this course on the SOLID Principles for C# Developers. The SOLID principles are comprised of five individual principles for writing better software, especially in object-oriented languages. They provide excellent guidance for C# developers who wish to develop software that is testable and maintainable. We'll begin the course with the first of the SOLID principles, which is the single responsibility principle. First, let's define SOLID real quick. It's a useful mnemonic acronym you can use to remember five important principles for software development. Since it's an acronym of other acronyms, technically SOLID is a macronym. These principles are single responsibility, open closed, Liskov substitution, interface segregation, and dependency inversion. You may hear these referred to by their individual acronyms such as SRP or ISP. So take note of the individual acronyms here. We'll start with the single responsibility principle. A common question developers have when learning about these principles is, When should I apply them? You'll find once you've learned these principles that it may be tempting to apply them everywhere all the time. Why? Because you watched a great Pluralsight course about them and learned how great they are, of course. Well, they can be great, but you should practice something I call PDD when considering whether to apply SOLID to your application. You may have heard of TDD, test-driven development, or DDD, domain-driven design, but maybe you're not familiar with PDD. PDD is pain-driven development. What that means is write your code using the simplest technique you know to get the problem solved. Don't worry about SOLID. Trying to apply all of the SOLID principles upfront is a form of premature optimization of your app's design. Instead, as your application grows and you continue to work with it, look for places where the app is painful to work with. That pain may exhibit itself as difficulty with testing or excess duplication, too much coupling, etc. When you feel that pain, see if any of the SOLID principles could be applied to alleviate the pain and improve your design.

Defining the Single Responsibility Principle
Robert C. Martin, also known as Uncle Bob, is credited with coming up with the single responsibility principle. He's defined it a number of times, but the definition I like best is this one. Each software module should have one and only one reason to change. This is a useful definition, but you probably still have some questions. What's a module in the context of a C# program? A module in this case might refer to a class or even a single function. Okay, but what about a reason to change? What does that mean, and how does it relate to responsibilities? Let's dig into this a little deeper. The individual classes and methods in our applications define what the application does and how it does it. We can often improve the design of our software if we're able to separate the what from the how. We do this through delegation and encapsulation. Classes should encapsulate doing a particular task in a particular way. When they're single-purpose, they're usually perfectly suited to this purpose and easy to use. Other classes can delegate the specific task to an instance of a class that encapsulates performing that task. When classes do too many things, they often end up coupling together things that shouldn't be related and make the overall class much harder to use. Trying to provide a general purpose tool results in additional complexity that a single-purpose tool wouldn't require. What is a responsibility? It's a decision our code is making about the specific implementation details of some part of what the application does. It's the answer to the question of how something is done. Some examples of responsibilities include persistence, logging, validation, and, of course, business logic. How is the application or even just this one class going to deal with persistence? Is it using files, a database, some Web API? What about logging? Is there some particular framework being used? How is input to the system validated? What about business entities? How do we know if they're valid for a particular operation? Where does the code go to enforce this? Mixed into all of these concerns might be business rules that actually define how the system should behave from the stakeholders perspective. They may not care about the low-level details of how files are stored or logs are written, but they definitely care that the system models the business problem correctly. SRP suggests that modules should have only one reason to change. Each of these decisions may need to be reevaluated in the future. Persistence might need to change from files to a database. The initial choice of logging may prove insufficient, and a new framework or provider may need to be added. Validation rules or even the way validation is performed might need to be updated in the future. And, of course, business logic is a broad category full of many possible responsibilities, any of which might change at different times and for different reasons. Keep this in mind. Responsibilities in your code represent things that may change at different times and for different reasons. Another way to think about this is that each responsibility is a different axis of change. The potential source of changes to your application can help you identify when you might be violating SRP. Even if you work for a small company, you might think about where change requests originate in terms of different executives within a large company. For example, the CIO may require a change to persistence because of a companywide change in database vendors. The security officer may require a more robust logging framework be installed to help detect and protect against attackers. The chief operations officer may be responsible for ensuring that your system integrates effectively with your company's newly acquired subsidiary requiring you to update your validation rules. And perhaps marketing just announced a special offering, and now the price calculations that your business rules model need to account for this new offer.

Coupling, Cohesion, and Concerns
The single responsibility principle is closely related to the concept of coupling. When two or more details are intermixed in the same class, it introduces tight coupling between these details. If the details change at different times for different reasons, it's likely to cause problems in the future with code churn in the class in question. Loose coupling refers to approaches that can be used to support having different details of the application interact with one another in a modular fashion. Typically, one class will be responsible for some higher-level concern and will delegate to other classes who are responsible for the details of how to perform lower-level operations. This follows another principle, separation of concerns. Separation of concerns suggests that programs should be separated into distinct sections that each address a separate concern or set of information that affects the program. Frequently, the specific implementation details of how a program does something can be thought of as low-level plumbing code. A key benefit of following separation of concerns is that high-level business logic avoids having to deal with such low-level code. Ideally, high-level code should not know about how low-level implementation details are implemented, nor should it be tightly coupled to the specific details. Have a closer look at this refrigerator in the picture and see if there any low-level plumbing concerns that are intermixed with other concerns like our food that we want to consume. We'll revisit this topic when we cover the dependency inversion principle at the end of this course. Another concept that is closely related to coupling is cohesion. Cohesion describes how closely related elements of a class or module are to one another. Classes that have many responsibilities will tend to have less cohesion than classes that have a single responsibility. In this diagram, you can see a class with several fields, two public methods, and a private method. The arrows identify which methods use which fields or other methods. This class is not very cohesive because its methods don't share much data or behavior with one another. We can reorganize this same diagram like so. Once grouped in this fashion, it's pretty apparent that Method 1 and Method 2 share very little with one another. In fact, we can re-factor them into separate classes that now are each much more cohesive than the original. You can visualize coupling between classes along with cohesion in this diagram. The relationships within each class represent cohesion, and as we just saw, if there are no relationships between elements of a class, it may be worth considering why they happened to be grouped together. Relationships between classes represent coupling. This coupling might be tight or loose depending on how it is implemented. In most cases, loose coupling is preferred because it results in code that is easier to change and test.

Demo: RatingEngine Insurance Sample
Rather than utilize examples that bear no relation to real-world business applications, this course is going to work with an application that's based on the real-world domain of insurance. I work with many clients in this industry, and it certainly has sufficient complexity to work well for the purposes of this course. For this demo, I've created a console application that accepts input in the form of a policy text file. The application evaluates the policy, applies some custom business logic to it, and produces a rating for the policy. As we look at the RatingEngine class, make note of how many responsibilities you think it has. You can view and download the samples for this course at github.com /ardalis/solidsample. The ArdalisRating application is a simple console application that has a RatingEngine, which is used to rate individual policies that might be submitted to my small insurance company. We'll start by looking at the program Main, which is the entry point for the application. It simply creates a new RatingEngine type and calls the Rate method. The result of the Rate method is that a rating property will be set. If the rating is greater than 0, then the system will output what the rating was. Otherwise, it will specify no rating was produced. Looking at the RatingEngine itself, it has one method of interest, which is the Rate method. Once the Rate method is called, it will output some stuff to the console to say that it's starting. It will load a policy file into a string and then deserialize that into a policy type using JSON to convert it. Then it will determine what type of policy is to be rated. The system currently supports several different policy types. You can see here the auto policy. In the case where it is an auto policy, it will do a little bit of validation to verify that certain key elements exist within the policy document, and then it will perform complex business rules to determine what the rating should be based on details provided inside of the policy. Obviously, in a real application, we would expect there to be a little more detail than you see here, but we're going to extend this some as we go through the course. The system also supports land policies. Land policies have different attributes applied on the policy that are required, and then it will do its own business logic to calculate what the bond amount for a particular land policy should be. And we also support life insurance options, which have their own set of input data requirements and validation and then perform their own custom business logic to determine what the rate should be for this particular policy. If the system does not recognize the type of policy being provided, it will simply log that out to the console, and once whatever type of rating has been performed, the system writes out that the rating was complete. It's a fairly simple application for the purposes of this demo. Hopefully, it adds enough real-world business logic and is combined with being simple enough that it doesn't confuse your ability to understand the SOLID principles with a lot of extraneous business logic details like, How is authentication going to be applied? Or what are the specific details of the complex SQL schema that's used to represent the rules that are applied to this particular type of policy? Imagine, and bear with me here, that all that stuff exists, but for the purposes of this course, we've stripped all of that extra complexity away so that we can just look at how to apply these principles in an easy-to-understand manner. Now, even with how simple this application is, I hope that you found that there were more than a few responsibilities inside of this RatingEngine class.

Problem Analysis
How many responsibilities did you find in RatingEngine. Here are a few that you might have noticed. Everywhere we're doing these Console.WriteLines is an example of how we want to perform logging for the system. The manner in which we're reading data from the file system instead of from perhaps some other source is a persistence responsibility, and if we changed our decision for how we wanted to persist that logic or how we wanted to input policies into this application, we would have to change that implementation detail and touch that code. We've also hardcoded a dependency on the JSON format. If later on we want to use YAML or XML or INI files or some custom binary format, we will again have to change this responsibility. You may have noticed there were a bunch of different business rules encapsulated inside this class as well. Some of these were represented by the different types of policy that were inside of that switch statement. Others were specific formulas that were used to arrive at different ratings. You also, hopefully, saw that there was a number of different kinds of validation going on usually ensuring that the particular properties necessary to perform a rating of a particular type of policy were present inside of that particular case statement inside the switch. And, finally, there was complex logic for things like how to determine someone's age baked into this class. That calculation, although it may not be likely to change, it also is a fairly low-level calculation that maybe doesn't need to be side by side with more high-level concerns of how we want to rate these policies. Responsibilities have a direct relationship with testability. When classes have many responsibilities, it becomes more difficult to test them. Especially when single methods are doing a lot of different things, it can be very challenging to write tests, in particular unit tests, for them. Generally, testing classes with many responsibilities results in tests that are longer and more complex. Frequently, the tests are brittle because they are coupled to the implementation, and a change to any responsibility might break tests for any other responsibility that's in that same method or class. This is an example of a test that we might write for the RatingEngine as you've just seen it. Notice that it needs to overwrite the policy.json file on every test run, making running tests in parallel impossible and likely creating problems for us at some point with locking and contention that might result in unexpected test failures.

Applying SRP to RatingEngine
Let's re-factor the RatingEngine with SRP in mind. This isn't a refactoring course, so I'm not going to go into detail on how to perform the changes. Check out my other courses on refactoring to dive into detail on when and how to best refactor your code. We're also not going to fully refactor the class just yet, but, rather, just demonstrate some incremental improvements. First, we can create a new class just for logging. It only has one responsibility. In fact, so far it only has one line of code. We can add a property to RatingEngine with this new type. We'll name it Logger. We find everywhere inside the RatingEngine that it's calling Console.WriteLine, and we replace it with a call to our new Logger.Log method. Likewise, we can perform roughly the same steps for persistence. First, create a new class that does just one thing, in this case, reading the policy from its text file. Next, we add a property of this type to the RatingEngine, and we use this property instead of working directly with low-level file IO libraries inside of the engine. After performing the same technique for how the policy string is deserialized into a policy type, the start of the Rate method looks like this. It's still doing the same work, but now it's not specifying how the work is done. It's delegating the details to other classes. Each of these other classes only does one thing, so they're extremely simple to work with and understand. This also has the benefit of making it very easy for us to name these new classes and their methods because when you only do one thing, it's pretty easy to come up with a name that describes that one thing that's being done. Each of these three new classes is easily tested, maybe not with what I would call a unit test, which wouldn't have any dependency on the file system or the console, but an integration or even manual test would immediately demonstrate whether each class is working properly. Also, because they're configured as public, settable properties, client code that works with the RatingEngine can swap in alternative test implementations of these three dependencies, if desired. An example of a unit test that wasn't easy to write before is shown here. Verifying that deserializing the policy works as expected can now be done in a very simple test without reliance on RatingEngine or on actual text files. We can specify whatever input string we want in each individual different unit test and verify that the expected policy type is returned as a result of the deserialization process that we're using. In this course, I'll show how applying the SOLID principles changes and improves the sample code, but we won't have time to focus on the refactoring techniques themselves. If you'd like to learn more about the refactoring process, I recommend these courses on Refactoring Fundamentals and Microsoft Azure Developer: Refactoring Code.

Key Takeaways and Summary
So far you've learned how the single responsibility principle can help improve the design of your applications. In the next module, we'll take a look at the open closed principle. Here are your key takeaways from this module. First, don't try to apply every SOLID principle upfront. Use them to eliminate pain by improving your design after you've written some working software. SRP states that each class should have one responsibility, which means it should have one reason to change. SRP also helps you achieve high cohesion within your classes, and we mentioned that you want to strive for loose coupling. Some of the other principles are going to help with this. Finally, keep your classes small and focused, which will generally make them much more testable as well. With these in mind, I hope you've enjoyed this module and you're ready to take the next step with me in learning about SOLID as we tackle the open closed principle.

Open / Closed Principle
Definition and Overview
Welcome back. In this module, you'll learn about the open closed principle, which describes how we should strive to structure our code in order to extend it in the future. The open closed principle, or OCP, is the second of the SOLID principles. OCP says that software entities like classes, modules, functions, and so on, should be open for extension but closed for modification. Dr. Bertrand Meyer is credited with originating the term in his 1988 book, Object-Oriented Software Construction. It should be possible to change the behavior of a method without having to edit its source code. Imagine you have a function in your program that does something. Now a new requirement comes along that needs to tweak how it works in certain cases. The typical approach most developers will take, which is perfectly reasonable, is to add some logic to the function so that it does one thing some of the time and something else at other times. This approach is fine most of the time and for simple functions. However, as complexity grows, you should think about how you might apply OCP so that you're not having to continually perform surgery on the same function every time a new requirement arises. Let's break this down a bit further. Open to extension in this case means that it's easy to add new behavior. If a module in our application is closed to extension, it simply means that it has fixed behavior. We can't change it. On the other side, closed to modification means that it's unnecessary to change the source or binary code of the system. Code that is closed to extension can't be changed without changing the code itself. So by definition, it is not closed to modification.

Benefits of OCP
You may be wondering, Why do we want our code to be closed to modification? The less we need to change the source of our code, the less likely it is that we'll introduce new bugs into it. We also won't need to redeploy that code, and that reduces the risk of downtime and the impact on downstream dependencies on that module. Code that is open to extension usually has fewer conditional statements than code that is closed to extension, which means it's probably simpler code that's easier to understand and test. And it's worth noting that when we find actual bugs in our code, even if it's otherwise closed to modification, it's perfectly acceptable to apply these directly to the code in question unless there's a better place to apply the fix. So, basically, even if you're following OCP, bug fixes should be an exception to that principle's rule, and you should be perfectly fine to apply those as actual changes to the source code when you need to. In the current implementation of RatingEngine, there's a switch statement that determines which policy type is being worked on. You can imagine that when the application was first written, it only supported one kind of policy, but as additional requirements came in and the business's needs expanded, other types were added. With each one, additional options were added to the switch statement, and we can expect this to continue if any additional policy types need to be supported. Given that's the case, the next time a requirement would cause us to further expand the switch statement, we should strongly consider refactoring to apply OCP. But why didn't the developers code it to be completely extensible to begin with? In this case, of course, it's so that I could have this slide to discuss. But in a real-world situation, it comes down to balancing abstraction with actual implementation and delivering working software.

Balancing Abstraction and Concreteness
Keep in mind that code that is extensible in any possible direction is infinitely abstract. You need to balance that abstraction with concreteness. And keep in mind also that abstraction adds complexity. Likewise, if you had code that only did one specific thing, this is what we would consider to be completely concrete. There's no abstraction. There's no way to change what it does. We want applications that can flex in the ways that we will need to as they are maintained and extended. We need to be able to predict where that variation will be needed and then apply the abstraction when the need becomes apparent. We don't want to have to develop a system with too much complexity up front that is trying to guess at every possible way that it might have to be extended in the future because it will be overly complex and difficult to work with. On the one extreme is code that does something in exactly one way. The only way to change its behavior is to change its code. A lot of code is written this way, and that's perfectly okay in many cases. Of course, when you use the new keyword, you're also being extremely concrete. You're gluing the calling code to a specific concrete implementation. Remember the phrase "new" is glue. And, again, this kind of code is fine until it isn't. Now let's look at the opposite extreme. A class like this one is extremely extensible. It can literally do anything because it doesn't actually do anything itself. 100% of its functionality is passed into it. As we'll see, parameterizing behavior is at the heart of many approaches to applying the open closed principle. Another example of extreme abstraction is this one, which relies on inheritance instead of composition and uses an abstract base class. If you're going to balance between extreme concreteness and extreme abstraction, how can you decide where to make your application extensible? One proven approach is to start out by being concrete and wait and see how the application evolves over time. When changes to behavior are needed, just make them in the code the first time or two. However, by the third modification, you should be strongly thinking about adjusting the code to follow OCP since it seems likely, based on past experience, that the application is likely to continue to change in this manner in the future. To use a baseball metaphor, think three strikes and you're out.

Typical Approaches to OCP
There are three typical approaches to applying the open closed principle. First, you can use parameters. By passing in different arguments to a function or method, we can change its behavior. This is one of the simplest approaches and one with which most developers are already quite comfortable. Secondly, you can use inheritance. Many design patterns leverage different inheritance approaches to facilitate OCP. Using object inheritance, you can change the behavior of the underlying type without having to change or even have access to that type simply by creating a new child class that inherits from it. The third approach is through composition and injection. Instead of placing logic directly within a class, the logic is provided by another type the class references. Instead of hardcoding the reference to this other type, the reference is provided through a technique known as dependency injection. We'll talk more about this technique when we cover the dependency inversion principle. C# also supports another form of extension through extension methods, which can add additional functionality to types without modifying the types themselves. Let's look at how we would apply each of these approaches to this extremely concrete class that we saw a moment ago. First, we can simply add a parameter. With the addition of a parameter, the Execute method can now print any kind of message to the console instead of just a fixed message. At the moment, changing the message is the behavior we're looking to extend, but we could also pass in some kind of StreamWriter type if we also wanted to be able to change where the message was sent. Right now we're fine with the fact that the current behavior of writing to the console is fixed. Another option would be to extend the Execute method using inheritance. In this case, we could mark the method as virtual and then override it in a child class to use a different message. A third approach involves composition and injection. In this example, we've pulled the responsibility for generating messages out into its own class called MessageService. The Execute method simply uses an instance of this class to get the message to display. The Execute method or the constructor could have simply instantiated the service using the new keyword, but this would have glued this class to that specific implementation. It would no longer be closed to modification for changes that might require a different kind of MessageService, and it would introduce tight coupling. Instead, the MessageService dependency is passed into the constructor and set to a private read-only field. This is a very common pattern you'll see in code that follows the SOLID principles and is an example of the strategy design pattern.

Prefer New Classes for New Behavior
Once you've identified an area where you'd like to apply OCP in your application, you should prefer implementing new features in new classes. Especially when working with large legacy code bases, this can be a way to add functionality without increasing the complexity of the existing system. Why should you use new classes for new features, especially in large legacy applications? First, you can design the new class from scratch so that its design perfectly suits the problem you're trying to solve. No need to work around existing code or bad patterns that might be there. Second, nothing in the current system depends on it because until now, it didn't exist. So, again, you're free to build it as you see fit. New classes also let you add behavior without touching existing code. In many legacy applications, touching existing code can be extremely stressful, and this lets you avoid that. Of course, any new class you create can immediately follow SRP even if the class that's using it has hundreds of responsibilities. Your new class can follow SOLID principles. And, finally, since you're designing it from scratch, of course you can write it so that it's easily unit tested. Even if the rest of the application is a big ball of mud that's painful to test, your new classes should be testable from the start. Learn more about maintaining legacy code by writing new code and new classes in this episode of my weeklydevtips podcast, which includes a full transcript.

Demo: Applying OCP to RatingEngine
Now let's look at how we would apply the open closed principle to the rating service sample application we reviewed in the last module. As it happens, the business has decided to get into the flood insurance business and needs the RatingEngine to support this new policy type. Currently, our RatingEngine uses the Rate method to load individual policy files, deserialize them, determine what type they are, and then perform the necessary logic to rate them. There are three types currently supported, all within this switch statement. Those types currently are Auto, Land, and Life insurance policies. If we want to add support to the business for flood insurance, we're going to have to add another case to this switch statement. We'll have to do that again for any additional types of policies that we need to support, and since we expect that our portfolio of services is going to continue to grow, we're taking this opportunity to apply the open closed principle and make it so that we can find a way to add additional extensions of behavior to the Rate method without having to continually come in here and change these individual case statements. The first step that we're going to apply is to take the logic from each one of these cases and move it into its own type. Once we've completed that refactoring, we'll be able to instantiate the appropriate type based on the policy type that we are trying to deal with. As we add additional kinds of policies that we want to support, we will then only need to add new classes. Here I've pulled the logic for the Auto policy out into its own class. This class takes in a reference to the RatingEngine so that we can set the rating property and the ConsoleLogger that's used to output things to the console. You can see that I've simply moved the logic that was inside the case statement into this type's Rate method. I've done the same thing for other types of Raters. As you can see here, there's an AutoPolicyRater, a LandPolicyRater, and a LifePolicyRater. If we look now at the RatingEngine, you will see the it's gotten much shorter, and it only has to worry about these three different types of Raters. However, we're not quite finished yet because we would still need to modify this switch statement in order to add support for flood insurance. So let's look at how we can create a factory that will eliminate the need for the switch statement inside of the RatingEngine. Using the factory design pattern, we're creating a new class called RaterFactory that has a method Create, which for a given policy will take in anything it needs, which in this case is just the engine, and determine which type it wants to return. So as you can see here, we have Auto, Land, and Life policies each being created by the RaterFactory. The switch statement still exists, but the switch statement now has moved from inside of the engine and into the factory. This is also helping us follow the single responsibility principle that we covered in the last module because now the RatingEngine is no longer responsible for determining which type and which logic should be used based on that type. Now determining what the type is is a responsibility that only the factory has. And instantiating the appropriate Rater type that we just created is now a factory responsibility as well. Once we have this factory in place, we can come back out to the RatingEngine and wire it up here in place of the switch. You can see that with this change to use the factory, the Rate method has become substantially simpler. Now when it comes time to actually apply the policy logic, we simply create a Rater from the factory and call its Rate method. The last step is to implement the FloodPolicyRater. Here you can see that adding the necessary logic for the FloodPolicyRater simply requires us to create a new subtype of the Rater abstract class and within it implement the Rate method. We can apply whatever business logic we want for how we're going to provide ratings for flood insurance. In this case, it's going to use the elevation above sea level to determine a multiple that will be applied to the rating. And once this is in place, the only other change we need to make is to add it to the factory. Inside the factory, now we've added a case for PolicyType.Flood, which we also added to our enumeration. And so when we add this type now, there's no possibility that we've accidentally broken the AutoPolicy, the LandPolicy, or the LifePolicyRater because they are each in separate types. With this in place, I hope you can see that the Rate method is now open to extension of different types of policies but closed against modification. We don't need to change the Rate method in order to add support for new policy types. More advanced students are probably already thinking that we can apply the open closed principle to the factory as well, eliminating the need for the switch statement by using reflection. In this case, we're going to use a naming convention to allow us to instantiate the appropriate class instance based on the name provided inside of the policy type in the JSON document. In the case where we don't find a matching class name, we'll just return null from the factory. This means that inside of the RatingEngine when we get back a Rater from the factory, we'll also need to check whether it's null. We can do that easily by just using the question mark operator on the Rater itself, in which case the Rate method will not be called if Rater is null. We can demonstrate that this works. If we take our policy document and see a valid one that's using flood insurance, if we run the application, we see that the flood policy is rated correctly. If we change to a type that doesn't exist and run it again, we see that no rating is produced, which is the expected behavior.

Applying OCP to Package Design
One area in which OCP is especially important is in libraries and NuGet packages. Whether public or internal, NuGet packages are closed for modification by their consumers. If new behavior is required, generally, the package author must add it and publish a new version of the package. Packages should also be closed for modification in a different sense, meaning they should avoid breaking existing client code that depends on them when they are updated with new behavior. Of course, packages should also be open to extension so that consumers can employ the functionality of the package in a way that suits their unique needs. Let's examine a NuGet package that follows the open closed principle allowing client code to extend the package while avoiding breaking existing clients as new versions add additional functionality. We're going to look at the ardalis/guardclauses NuGet package to see how this was implemented and see if it's a model that you might be able to use in your own application. Guard clauses are a name for a simple pattern where you check for inputs to see whether or not they're valid and would throw an exception if they're not. It's a useful technique in order to reduce complexity inside of your code. This guard clause's NuGet package allows you to use a consistent way of applying this technique inside your code. For example, you can see in the usage block here that before we process an order, we want to ensure that the passed-in instance of an order is not null. We do this by calling Guard.Against .Null. Inside this package, there are a number of common supported guard clauses for things like Null, NullOrEmpty, NullOrWhiteSpace, etc. However, inside of your own application, you may have common checks that you need to apply. You can easily do this by extending this with your own guard clauses, and the approach in this case is to use extension methods. By extending the IGuardClause interface, you're able to produce any type of Guard.Against .Whatever method that you like. In this case, I created an extension method called Foo, and it just checks to see whether the input is foo, and if it's not, then it will throw an exception. The usage for this is to simply say Guard.Against .Foo and pass in the relevant variable and the variable name. This is just one example of how you can add extensibility to a NuGet package so that it can stay open to extension even though, of course, it's closed to modification unless you want to come out to this GitHub repository and add a new pull request.

Key Takeaways and Summary
Here are some more resources you can use to learn more about the open close principle. First is an article on Hacker Noon by James Ellis Jones on why the open closed principle is the one you need to know but don't. Next, there's a great article on the Open Closed Principle by Uncle Bob Martin, which you'll find here. And then there's the Open Closed Principle by Jon Skeet, which you'll find at this URL. So far, we've looked at the single responsibility principle, which recommends keeping our classes small and focused on one kind of thing, and the open closed principle, which describes when and how we should use abstraction to make our design more extensible. In the next module, we'll learn how the Liskov substitution principle applies to our use of different types in our applications. Your key takeaways for the open closed principle are to, first, make sure to solve the problem at hand using simple concrete code. Don't try to make your code open to extension in every possible direction because doing so will make it way too abstract. Next, identify the kinds of changes that your application is likely to continue needing. Generally, you can base this on the actual changes that you're having to make to the code as new requirements are discovered and implemented. Try to avoid prematurely speculating without actual requirements. Finally, modify the code to make it extensible along the axis of change you've identified. You'll want to use one of the techniques shown here in this module, or one described in the refactoring or design patterns library courses on Pluralsight. These will make it possible to extend your application's behavior in a particular way but without the need for you to modify its source. Thanks for watching. I hope you've enjoyed this module. And in the next module, we'll get started talking about the Liskov substitution principle.

Liskov Substitution Principle
Defining the Liskov Substitution Principle
Welcome back. In this module, you'll learn about the Liskov Substitution Principle, which provides guidance on how to properly use inheritance in object-oriented languages like C#. The Liskov Substitution Principle, or LSP, is the third of the SOLID principles. As we we'll see, LSP also tends to produce code that better follows the Open/Closed Principle we just learned about in the previous module. The original definition of the Liskov Substitution Principle reads Let phi of x be a property provable about objects x of type T. Then phi of y should be true for objects y of type S where S is a subtype of T. Was that perfectly clear? Yeah. Many programmers may not immediately understand what's meant by this, so a more approachable definition is simply subtypes must be substitutable for their base types. Just like the Open/Closed Principle, this principle has its origins in the 1980s, so it's not a particularly new idea. Barbara Liskov introduced the principle in a conference keynote in 1987.

The Problem with Basic IS-A Inheritance
Basic object-oriented design often teaches developers to think about objects and their relationships with one another using two characteristics. Inheritance, the is a relationship, occurs when something is a kind of some other thing. For example, an eagle is a bird. Properties, on the other hand, exhibit a has a relationship with something else. For example, an address has a city associated with it. The Liskov Substitution Principle states that the is a relationship is insufficient and should be replaced with is substitutable for. There is a classic shape-based example that's often used to demonstrate LSP. It involves a rectangle and a square or sometimes an ellipse and a circle. First, note be definition a rectangle has four sides and four right angles. Similarly, a square has four equal sides and four right angles. In geometry, all square are rectangles, so for any given square it's true that a square is a rectangle. It clearly exhibits the is a relationship that is often used to describe basic inheritance design in OO languages like C#. We can implement a Rectangle class in this fashion. It's exposes properties for Height and Width. Other classes can operate on instances of this rectangle type, such as this AreaCalculator. You can see that it uses the rectangle's height and width to calculate and return the area of the shape. Since we know from geometry that a square is a rectangle, we can create a class Square that inherits from Rectangle. However, while a square does have a height and a width, they must be equal. If they're not, then the shape isn't a square. We enforce this constraint but ensuring that any time the height is set, the width is set to the same value. We do the same with width so that when it is set height is set to the same value as well. This ensures instances of Square are always squares. The problem with this design occurs when code expects to be able to work with a rectangle, but an instance of a square is used instead. In the example shown here, the code that is expecting to work with a rectangle instance is setting the width and height to 4 and 5 respectively, which the code then expects to result in a shape that will have an area of 4 x 5 = 20; however, the actual result is 25. In this example, it might be obvious that this is going to happen because you can see that Square is being instantiated right there on the first line, but in the case where this code could exist inside of a method where Rectangle is being passed in as a parameter and instead an instance of a square is passed in, it would not be nearly as clear where the problem lies. What happened? We know that the Square class has a rule that its side must be equal. This rule must always be true for this type, so we call it an invariant. But we inadvertently broke an invariant of rectangles, which is that its sides can change independently from one another. Rectangles do not expect their values for height and width to be coupled to one another. The current design approach breaks this invariant for rectangles. As a result, when we try and substitute an instance of a square into code that is expecting to work with a rectangle and its invariants, we get unexpected behavior. The square is not substitutable for the rectangle everywhere a rectangle is used and thus violates LSP. One simple solution to this problem is to eliminate the Square class entirely and instead just denote whether a particular instance of a rectangle is a square using a flag. Another option would be to have Square as a separate type without any dependency on Rectangle. This would require a separate CalculateArea method for squares, but eliminates the LSP violation and provides a clearer representation of a square as an object. There's really no need to store two separate values for height and width for a square since by definition they will always be duplicates of one another.

Detecting LSP Violations in Your Code
In most business applications, it's uncommon to be dealing with geometric shapes, so let's consider the ways in which you're likely to encounter LSP violations in real-world applications. First, if you're checking the type of a variable using the is or as keywords inside of code that should be polymorphic, meaning it should work with a type or any subtype of that type, that's often a clue that LSP is being violated. We'll see an example of this in the next slide. Another kind of LSP violation is null checks. You'll see that this code often looks very similar to type checks. The third common symptom of LSP violations is the NotImplementedException. Pretty much any time you see this exception, it's an indication that an interface or base class was only partially supported, and some on its features were left unimplemented. By definition, this type cannot be substitutable for its interface or base class for all places where it might be called. In the next module, we'll see how this is also a symptom of violating the Interface Segregation Principle. In this code, you can see a loop over a collection of employees. The actual type of each individual employee should not be important to this foreach statement. Any subtype should be substitutable for the base employee type. However, there is an if statement checking the type to see if it is specifically the Manager subtype, and if it is, the loop treats it differently and calls a different method; otherwise, the standard PrintEmployee method is called. The biggest problem with this kind of code is that it tends to repeat itself. Any time you work with employees, you might have to perform a check to see if it's the special Manager type, and if so, do something different. Later, you might add additional subtypes like Director or Executive, and you might have to revisit everywhere these checks exist to add additional behavior to support these new subtypes. Obviously, this violate the Open/Closed Principle we covered in the last module since you would need to change the code itself to modify conditional statements in many places anytime you further extended employee. This kind of LSP violation can be address by ensuring all subtypes of employee are substitutable. One way to do this would be to have each separate type implement custom functionality in its own way. In this case, the Print functionality could be moved from a helper into the type itself. Be careful not to violate the Single Responsibility Principle when following this approach, however. Another option is to adjust the helper method so that it can work with any kind of employee. In this case, we may only be moving the problem code, but the code in question, the foreach loop, now no longer violates LSP. And if the helper method was being called from many places in our code, we've now consolidated all of the employee type checks to one place inside that helper method. Note that checking for nulls is essentially the same behavior as checking the type. If you have one set of behavior you expect to call when you have an instance and a different set of behavior you want to call when the instance is null, that's an LSP violation as well. Generally, in C#, nulls are not substitutable for actual instances when we want to access properties or call methods on that instance. C# offers many features now specifically to better deal with null values, and you can also use design patterns like the null object pattern to avoid the need for null checks. We'll see an example of this shortly. I've written an article on how nulls break polymorphism and the Liskov Substitution Principle, which you'll find online here at aradlis.com. You can also learn more about the Null Object Pattern in the Design Patterns Library here on Pluralsight. Just search it for the Null Object Pattern. The third way you'll often detect LSP violations in your code is when you see not implement exceptions. For example, imagine you have an interface like this one in your system which supports two methods for sending notifications, SendText and SendEmail. An actual implementation of this service which might be used in a particular place in your code isn't SmtpNotificationService. It implements the INotificationService interface, but only works for sending emails. The SendText methods just throws a NotImplementedException. This means that this SmtpNotificationService is not substitutable for INotificationService anywhere it might be used because some places might call SendText. You've heard me say that nulls break polymorphism. That's not strictly true since a null instance is a valid thing in C#'s type system. You could argue it would be a bit more accurate to say that nulls break LSP. But LSP is a subset of polymorphism. All types that follow LSP also support polymorphism, and, more importantly, anywhere that you want to use polymorphism, you almost certainly want substitutability. You want LSP. Thus, it's true that null references and other LSP violations break polymorphism because polymorphism that doesn't follow LSP is itself kind of broken. It doesn't really work in every case, as we've seen in a number of examples here already.

Fixing LSP Violations
When and how should we fix LSP violations in our code? First, follow the Tell, Don't Ask principle. Don't ask instances for their type and then conditionally perform different actions, but instead encapsulate that logic in the type itself, and tell it to perform an action. Packaging state and behavior together is a basic principle of object-oriented design, and Tell, Don't Ask is a great way to remember to do this. You can address null references by using C# features for dealing with null values like nullable reference types, null conditional operators, and null coalescing operators. You can also use guard clauses, like we saw in the previous module, to use exceptions to prevent null values from reaching the primary logic in your methods. And the Null Object Pattern can also provide a useful way to prevent null checks and provide an LSP compliant instance to use when you might otherwise have used a null. Finally, whenever you implement an interface or inherit from a base class, make sure you fully implement it. If you're finding this difficult, it's probably because the type in question is violating the Interface Segregation Principle, which we'll learn more about in the next module. In the original sample code, the PrintReport method was checking whether the employee instance was of type Manager. It did this by asking it its type using the is keyword and then conditionally calling a different method based on the response to this question. The logic of how and when to print an employee or a manager were split between the Employee type and the Print methods. When Tell, Don't Ask is followed, the PrintReport method can simply loop over the collection of employees and tell each one to print itself. Whether the particular instance is an employee or a manager is irrelevant to the PrintReport method, and the logic, specific to each type, now is encapsulated within that type, resulting in a more modular and cohesive design.

Applying LSP to ArdalisRating
Now let's look at how we can apply LSP to the ArdalisRating application. Users have reported a small bug that we introduced when we made our updates from the last module that we now need to fix. In the last module on the Open/Closed Principle, we introduced a factory to create different policy rater instances. I showed how we could use reflection and a convention so that we wouldn't even need a switch statement inside the factory. It could follow OCP as well. Of course, if we didn't find the matching type to create, an exception would be generated. In this case, we simply returned null. I noted that in RatingEngine we could work past this null by using the null conditional operator on the rater instance. The code runs and doesn't produce a rating, but its behavior isn't 100% the same as the original code. Of course, the original code wasn't easy to test, so we didn't notice the problem immediately. But now our users have reported the bug to us, and we need to fix it. Let's take a look at the original code for the Rate method of RatingEngine. In this original code, if a policy specified a type that wasn't recognized, we would log Unknown policy type. We're no longer outputting this message in the case where the type doesn't match. Okay, that's no problem. We can put in an if statement to check for this in the RatingEngine. Let's go back to our new code. Right here, we can simply change this code to add a null check and output the expected message in the case where the rater comes back as null. With just a couple of lines of code, we've fixed the bug. Now when the rater comes back null we can log out Unknown policy type to the console; otherwise, we'll go ahead and just call the Rate method on the rater that the factory returned us. This is great, but now we're violating LSP because we have to treat null differently from how we treat other instances. Since the only behavior that we need in the case of an unmatching policy type is to log something and take no other action, we can easily get this by applying the Null Object Pattern. To do this, we put the behavior we expect when we don't find the matching policy rater into its own type, which we'll call UnknownPolicyRater. Then, we modify the factory to return an instance of this type any time we don't find a matching rater. That means that instead of returning null in our catch block, we'll return a new instance of this rater type. Notice that after this change the RaterFactory no longer returns null under any conditions. That means we can get rid of the null checks in a RatingEngine and just let the rater encapsulate the behavior of what do when no match is found. This change reduces the complexity of the Rate method so that it can only deal with raters and just call the Rate method on that rater without having to worry about nulls or other special cases.

Key Takeaways and Summary
Now we've covered SRP, OCP, and LSP of the SOLID principles. Notice how the different principles relate to one another. We saw in this module how LSP violations can result in problems with following the Open/Closed Principal, and I alluded to the fact that some kinds of LSP violations are a result of Interface Segregation Principle violations, which we'll look at next. Your key takeaways for this module on the Liskov Substitution Principle are first that the is a relationship is insufficient for object-oriented design. You need to ensure your subtypes are substitutable for their base types. You also learned that it's not just about whether the code can compile or whether it technically has an is a relationship with its base types. Types often have invariants that must be maintained in which code that uses these types depend upon. You must take care not to break these invariants when you create subtypes or implement interfaces. Symptoms of LSP that you may find in your code are type checking, typically using the is and as keywords in C#; null checking, particularly when special behavior is done in the case of null rather than just throwing an exception; and NotImplementedExceptions, which almost always indicate that a type isn't fully substitutable for its base class or interface. That's it for the Liskov Substitution Principle. Stay tuned to learn more about the I in SOLID, the Interface Segregation Principle in the next module.

Interface Segregation Principle
Defining the Interface Segregation Principle
Welcome back. In this module, you'll learn about the interface segregation principle, which describes how we should design and use interfaces in our applications. The interface segregation principle is the fourth of the SOLID principles. In the last module, we saw how Liskov substitution principle is sometimes violated when interfaces are only partially implemented. We'll dig into this further in this module as well. The interface segregation principle states that clients should not be forced to depend on methods they do not use. The corollary to this is that you should prefer small, cohesive interfaces to large, fat ones. Recall in the first module on single responsibility that we broke up our classes into smaller, more cohesive ones. This is very similar. To be clear, what do we mean by interface in the interface segregation principle? Remember, this principle applies to any object-oriented language, not just C#. Certainly in C#, the interface type and keyword is one kind of interface described by ISP, but it also refers to the accessible interface of any class. A types interface in the context of ISP is whatever can be accessed by client code working with an instance of that type. Now that we've defined what we mean by an interface, what is a client in this case? The client is simply the code that's interacting with an instance of the interface. It's the calling code. Don't confuse it with client/server architecture or similar definitions of client. If you have code that works with an instance of a type, whatever you can call on that instance is its interface, and your code is the client. ISP says your code shouldn't depend on methods of that instance that it does not use.

The Problem with ISP Violations
What's the problem with large interfaces you ask? A common example I use to illustrate the issue is the MembershipProvider class that shipped with ASP.NET 2.0. The membership feature was a much-needed addition to ASP.NET at the time, but out of the box, Microsoft only supported SQL Server as the back end store. If you wanted to use some other storage mechanism like Oracle or Active Directory, you had to implement your own provider by overriding the MembershipProvider type. Unfortunately, the MembershipProvider class is pretty big. You can see an override of it on the screen here. It has about 7000 methods it seems like. Okay, maybe not quite that many, but it has a lot of methods you need to override in order to fully implement your own provider. And you remember from the previous module that not implementing some methods means you're breaking LSP, which is certainly not ideal. What if all your code needs is to log the user in? Should you have to depend on this massive interface? Violating the interface segregation principle results in classes that depend on things they don't need and don't use. This increases coupling and makes it harder to change or swap out individual implementations because the number of clients that might break is much larger. That's because it includes clients that depend on the interface but aren't even using some parts of it, which might be the parts that you're changing. For example, what if you want to implement your own membership provider, but the only thing you care about is wiring up login so that you use Pluralsight accounts for the login and logout functions? In that case, the only methods you would need in order to support this functionality would be login and logout. Pluralsight's web application would handle all the other stuff like Registration and Forgot Password and things like that. But if you're using the MembershipProvider base class, you'll be forced to implement dozens of methods just to get this functionality. Large interfaces result in more dependencies. More dependencies result in more coupling, code that is more brittle because of the increased coupling. Client code that depends on large interfaces can be more difficult to test since fake implementations might require more work, and since the code that is using these large interfaces tends to be more coupled. And changes to types that implement fat interfaces will involve more testing of downstream dependencies, thus making deployments more difficult and riskier.

Detecting ISP Violations in Your Code
How can we detect ISP violations in our own software applications? First, look for large interfaces. Large is intentionally vague, but cohesion and experience can be a guide. Also, remember to follow pain-driven development. If you are looking at your implementations of an interface and find that there are NotImplementedExceptions in them, that's telling you the interface was bigger than at least some of your clients needed. And, likewise, if you look at your client code and you see that it's only using a small subset of a larger interface, that's another indicator that you're probably violating ISP. Remember this interface from the last module on LSP. It's a notification service interface that includes only two methods. It's certainly not a large or fat interface, but it lacks cohesion. This becomes clear when you have some client code that only needs to send emails but isn't interested in sending text messages. Suddenly you end up with implementations like this one that only partially implement the interface and use NotImplementedException for the rest. You can easily address problems like this by breaking up the interface into smaller, more cohesive interfaces. In this case, each interface, the IEmailNotificationService and the ITextNotificationService, has only one method. But this technique also applies to larger interfaces that have several methods that can be broken up into smaller interfaces. Now you may be wondering, What about legacy code that's already using the original INotificationService interface? If I replace it with these smaller interfaces, that code's going to break. And since I can't go and fix all those places, I can't really use this technique. But wait. C# has supported multiple interface inheritance from the start. You can use this to pull out any number of smaller interfaces from a larger one and then simply add the smaller interfaces to the original interface using inheritance. In this example, you can see that the INotificationService still exists, but now it inherits from IEmailNotificationService and ITextNotificationService. The body of this interface no longer defines any methods at all, but it continues to have the same signature that it had before. Any clients that depended on INotificationService will continue to work and compile just like they did before we made this change. Of course, this only works if you own the large interface. You can't apply this technique to a large interface you're forced to use as part of a third-party framework or SDK. In that case, you're probably best to use the adapter design pattern and introduce your own interface that you do control.

Fixing ISP Violations
As we've seen, ISP is related to Liskov substitution principle. Large interfaces are harder to fully implement and, thus, more likely to only be partially implemented and, therefore, to not be substitutable for their base type. The interface segregation principle also relies heavily on cohesion, which we discussed in module 1 on the single responsibility principle. Small, cohesive interfaces are preferable to large interfaces whose methods are only loosely related to one another. Finally, when it comes to addressing problems with ISP, remember to follow pain-driven development, or PDD. You shouldn't break up interfaces just to satisfy the principle but, rather, use the principle to help identify the source of some pain you're experiencing with the code base. If you try and preemptively follow ISP everywhere, you could end up with a bunch of single method interfaces that are much more difficult to use and group together and understand than a few cohesive interfaces. Once you've identified a problem in your code's design that results from an ISP violation, you can address it using one of these approaches. First, you can break up larger interfaces into smaller ones. If the original interface is still being used, you can compose it from the smaller ones for backward compatibility. For large interfaces you don't control, create small, cohesive interfaces that follow the adapter design pattern. Your code should work with the adapter interface that you control, and it, in turn, can work with the original large interface. Only the adapter should know about the underlying large interface. Finally, it's easy to follow ISP if you let client code define the interfaces the code will work with. In fact, it's impossible to violate the interface segregation principle, which says the client shouldn't depend on methods they don't use, if clients are defining interfaces to include exactly the methods they actual use. Think about how and where you're defining the interfaces you use in your application and consider whether it would make sense to adjust them to suit the code that's using them more closely. This will have an impact on where those interfaces are defined in your solution structure. Since wherever possible client code should define and own the interfaces it uses, it follows that these interfaces should be declared where both client code and implementations of the interfaces can access it. To learn more about how to structure your solution to support ISP and, as we'll see in the next module, the dependency inversion principle as well, check out the Microsoft Reference Application eShopOnWeb. It has an associated eBook that I authored and should help you with architecting your solution properly. You can also look at my Clean Architecture Solution Template, which you'll find on GitHub. It lays out a solution for you with interfaces and infrastructure placed where they should in order to follow SOLID principles. And then on Pluralsight, you might want to check out my Creating N-Tier Applications in C# course followed by the Domain-Driven Design Fundamentals course for more on how to structure your projects and solutions. You'll also be able to learn more about the adapter pattern in the Design Pattern Library.

Demo: Applying ISP to ArdalisRating Sample
Now let's look at how we can apply the interface segregation principle to the ArdalisRating sample application we've looked at throughout this course so far. Since we last looked at the code, some more features have been added, and the development team has introduced a RatingContext class for the RatingEngine to use. However, now it's time to make some additional updates to the application. And this Context class is perhaps a little bit too bloated for what we need. The interface segregation principle often gets overlooked in terms of real-world utility. So I'm making a strong effort to really showcase its importance in this demo. The RatingEngine class shown here used to have separate properties for its logger, policy source, and serializer. Over time, the team supporting this project pulled these into a single Context type shown here and made them part of the IRatingContext interface. There's a DefaultRatingContext class that implements this interface for this application. There are other applications that have different implementations of this DefaultRatingContext. Looking at the Rate method on RatingEngine, we see that now almost every line calls a method on this new Context interface. Likewise, the RaterFactory type we introduced in module 2 also uses the Context interface now, as do the individual Rater types like AutoPolicyRater. The base Rater class still exposes a ConsoleLogger probably for backward compatibility, but now that logger just comes from the context. This kind of Context class is not unusual, especially in applications that don't use dependency injection. The convenience of having a single class in which to put all dependencies and common code frequently turns the class into a junk drawer of methods and almost always ends up violating the single responsibility principle. The class also tends to get depended on by all kinds of other classes, as you can see here, making it very difficult to change in the future for fear of breaking any of its many dependencies. Looking at the interface itself, we see that it has nine methods and properties with responsibilities ranging from logging to data access to serialization to object creation. It also exposes properties for the engine and logger it's using. Having side-by-side methods for loading data from different sources or deserializing using different formats is a problem we'll address in the next module. Exposing both a Log method and the Logger itself makes for a clumsy interface since client code isn't led to use the Log method directly versus the Logger property's Log method. Generally, you don't want to give your clients multiple ways to accomplish the same task in a single interface. It just causes confusion and potentially bugs. The Logger property probably only exists to support some backward compatibility, in this case, the fact that the Rater class requires a logger to be provided when it's created. Now let's look at the implementation, DefaultRatingContext. Sure enough, if we scroll through it, there are a couple of NotImplementedExceptions in this implementation. That alone is a sure sign that this interface is too big. A quick review of the code also reveals that the Log method and the Logger property aren't even linked together. They each instantiate their own separate ConsoleLogger. This could easily result in bugs in the future if they were to be changed independently from one another. Since the main functionality of our system is done by individual Rater classes, it would be great if we could easily unit test these classes. Unfortunately, the dependency on IRatingContext and the use of the concrete ConsoleLogger type make writing these tests difficult. Let's apply ISP to the Rater class and see how that improves the design and allows us to better unit test some of the code. First, we need to identify what Rater instances are using. Which methods off of IRatingContext do they require? Starting by looking at the abstract base class Rater, we can see that it requires an IRatingContext, and from it, it uses the Logger property. Looking at an actual Rater like AutoPolicyRater, we discover that the only method on IRatingContext being called is UpdateRating, and the only method on the Logger being called is Log. With this in mind, we could create an interface with just these two methods on it. But combining UpdateRating and Log into one abstraction doesn't sound very cohesive at all. I think we'd be better off with two different interfaces. We'll start by creating an ILogger abstraction with the method Log. We then update the ConsoleLogger class to use this new interface, which we made sure already matched its existing signature. Next, we modify Rater to use ILogger instead of ConsoleLogger. Now we have a few choices for how to initialize this ILogger. We can just instantiate it in Rater, which will glue Rater to the ConsoleLogger implementation. Remember, new is glue. That doesn't give us much benefit for having an interface. Or we can make it a settable property and default it to ConsoleLogger. That will give us the current behavior in production just like we have today but would let us modify the property in our tests. Or we can follow the explicit dependencies principle and take the ILogger as a constructor parameter. We'll learn more about this in the next module. For now, we'll go the property route. To finish this change, we just need to update all the calls to _logger.Log to use Logger.Log. We also can remove the Log method from IRatingContext and, instead, have that interface inherit from ILogger. At this point, we can run the application and our rather small test suite and see that things still work. Next, we can look at the updating of ratings. We want to pull out an interface to replace UpdateRating. Naming things is sometimes hard. For now we'll just call the new interface IRatingUpdater. We pull the UpdateRating method from the IRatingContext interface and once more have that big interface inherit from the new one for now. Now we can go back to Rater and have it use the new IUpdateRating interface instead of IRatingContext. We follow this change up by changing the individual Rater instances, such as AutoPolicyRater as well, so that they use IRatingUpdater and they call the IRatingUpdater's UpdateRating method to perform their logic inside of their individual Rate methods. With that done, at this point, it's pretty easy to write tests for the individual Rater types like AutoPolicyRater. We can set the Logger property to a fake logger type that keeps track of the messages it sent and confirm the expected messages logged when validation fails for instance. You can see the scenario here where, if the Make does not exist, we're going to log Auto policy must specify Make, and then return. Creating a test for this requires that we use a fake implementation of the logger that will let us verify what messages were recorded. Then inside of our test, we can use this fake version of the logger, call the Rate method with a policy that does not specify Make, and then assert that the last message that was logged is the one we expect. We can see our test passes, which gives us some confidence that it's doing the right thing. This is not a unit testing course, but it's worth pointing out that you could also use mock objects instead of the fake implementations to make these types of tests a little bit quicker to write. Looking back at the AutoPolicyRater's Rate method, we would also like to write tests that confirm that we specify the correct rating for the Make of BMW with different deductibles. We can do this by creating a fake version of IUpdateRating and then verifying what its value was set to. Here I've created a FakeRatingUpdater that implements the IRatingUpdater interface. Instead of actually updating the rating somewhere, it just updates its own property, which you'll notice starts out nullable, so we can verify whether or not it had been set at all as part of our tests. Now we can write a test that creates a policy that is a BMW Make with a deductible of 250, and we expect based on the system under test that this is going to give us a rating of 1000. We'll go ahead and build and run the test. Whoa, and this test actually fails. We expected 1000, but the actual is 900. Let's look at the AutoPolicyRater, and we can quickly see the problem here is that we're calling UpdateRating twice. We neglected to add a return statement or, alternately, to put this other section in an else block. I prefer the return statement because then if we add additional rules, this will just return out and not continue to process them, so we'll short-circuit the processing of additional rules. This will keep the code a little simpler as it expands. So it turns out that making this code easier to test meant that we actually wrote some tests, which in turn meant that we just discovered this bug. We can run the tests again and verify that we did, in fact, fix the issue. We'll be sure to write some more tests for the different types of Raters to make sure that they're all working properly. Okay, so now our Rater types depend on only what they need so they follow ISP. They're also easier to test. The last thing we can do is revisit IRatingContext and see if there's anything still there that we no longer need. It looks like we can now remove the IRatingUpdater interface. Looking at the DefaultRatingContext, it turns out we can also remove the Logger property since it's no longer being used either. The last thing we'll need to do before we're finished here is make sure that we actually have an implementation of the IRatingUpdater since currently we only have an interface. Looking back at IRatingContext, we see that now it has just six methods and properties, which is certainly an improvement. One last note, you may notice that our project is starting to get a little bit cluttered by all these different types of files. We'll address this in the next module as well.

Key Takeaways and Summary
So far we've learned about four of the five SOLID principles. Some of the concepts described in SRP and LSP have returned in this module on interface segregation. We'll see more of these relationships in the final module on dependency inversion. Your key takeaways for the interface segregation principle are, first, to prefer small, cohesive interfaces to large, expansive ones. Following this rule helps achieve the single responsibility principle and to follow the Liskov substitution principle. Finally, when you do find that you have existing large interfaces that you need to break up, you learned a couple of different techniques for doing so. You can use interface inheritance and use smaller interfaces that the larger one then inherits for backward compatibility, or you can use the adapter design pattern to allow new code to depend on a small, cohesive interface without breaking existing code that may use the larger interface. That's it for this module. I'll see you again to wrap things up in the dependency inversion principle module coming up next.

Dependency Inversion Principle
Defining the Dependency Inversion Principle
Welcome back. In this module, we're going to discuss the dependency inversion principle, which is critical to creating loosely coupled, maintainable software of any significant size. The dependency inversion principle is the fifth and last of the SOLID principles. We'll see that it builds on several other principles we've discussed already. The dependency inversion principle, or DIP, states that high-level modules should not depend on low-level modules. Both should depend on abstractions. It goes on to say abstractions should not depend on details, but rather details should depend on abstractions. Let's break this down a bit. How do I know if something depends on something else? How can you tell? There are two kinds of dependencies in C#, compile time and runtime. The dependency inversion principle mostly has to do with compile time dependencies. Of course, the right implementations, low-level details and all, must exist and perform correctly for the application to work as expected when you run it. If your application is built using multiple projects in a solution, your project references will point in the direction of your dependencies. If you follow DIP, these references should point away from your low-level infrastructure code and toward your high-level abstractions and business logic. I mentioned these resources in the last module, but they're worth repeating here. If you don't set up your solution properly, it can be extremely difficult to follow the dependency inversion principle. Check out at least Part 1 of the Creating N-Tier Applications in C# course and take a look at one of the sample applications listed here to see how to properly structure your solution to follow these principles. The key is to ensure your infrastructure project depends on interfaces that live in a separate core project, and it should have the abstractions your front end application will use. Avoid having your UI project use infrastructure concerns like data access libraries directly. It's also important to clarify what's meant by high level and low level. When we talk about high level, we're talking about high-level constructs in our application that tend to be more abstract. They relate more to the problem domain and our business rules. These things should generally be more process-oriented than detail-oriented, and they're further away from input output or I/O, things like forms and buttons or files and databases. On the other end, low-level concerns are closer to the metal. These are concerned with IO details. Is this input coming from a file or from the console or from a database table? What specific serialization format is being used, etc.? A lot of low-level code is commonly referred to as plumbing code. The high-value code is your business logic, but nobody can use that business logic if it doesn't communicate with a UI or some kind of service or something outside of your application. So you need plumbing code to connect your beautiful business logic to the rest of the world. Low-level code is all about the details of how your software interacts with things outside of its control, such as external systems and hardware devices. Recall in module 1 on SRP, we talked about separation of concerns. You can see now that the dependency inversion principle is all about doing this. High-level concerns like your domain model or business rules should be kept separate from low-level concerns like plumbing code that knows about all the details of your UI or persistence layer. Your system's abstractions are generally going to be high-level concerns. So make sure they don't depend on low-level concerns. But wait. Just what is an abstraction? How will I know one when I see one in C? Abstractions in C# refer primarily to interfaces and abstract base classes. Interfaces are generally preferred because they don't require object inheritance. So they're a bit more flexible. Essentially, the things you can instantiate are concrete while the types that describe a way to work with that type but don't actually perform the work are abstract. The abstractions just define a contract, a way of working with a type without actually specifying how that work is going to get done by having a specific implementation of that contract. What about details? What are those? Abstractions shouldn't be coupled to details. That is, they shouldn't know about the specifics of how they are implemented. Abstractions describe what. Maybe it's send a message or store a customer record. That's what needs to happen. Details specify how. They would say send an SMTP email over port 25 or serialize customer to JSON and store it in a text file. That's describing how to store a customer record, whereas the abstraction doesn't really care about the details. It should only care that the customer record gets stored. Let's look at an example. The IOrderedDataAccess interface shown here is an abstraction for accessing ordered data. Because it's an abstraction, it shouldn't care how that data is stored, so long as it's able to provide the data. This interface, however, returns a SqlDataReader and takes in a SqlParameterCollection exposing implementation details and making the interface much less reusable. What's more, any client code that wants to use this interface must now take a dependency on ADO.NET in order to use it. Modifying the interface like so corrects this problem hiding the details of how the data might be stored or accessed.

Properly Structuring Your Dependencies
Some examples of low-level dependencies in an application include the database, the file system, email sending or receiving, Web API consumption or hosting, configuration details like reading a particular setting from a particular file, and system clock access since it's an external concern that is difficult to change or control. Be especially mindful of hidden dependencies in your code. Watch out for direct use of these low-level concerns from your high-level concerns. Usually these will take the form of static calls or the new keyword being used to directly create instances of low-level types. These direct dependencies cause pain because they introduce tight coupling. Since they're hidden, not explicitly requested in a constructor of the class using them, they're more difficult to isolate and unit test. And, frequently, when you're calling these static methods or creating these low-level types directly, you're doing it over and over again, so there tends to be a lot of duplication of this kind of thing in the code base. I've mentioned this before, but just remember, new is glue. Using new to create dependencies in your system glues your code to that dependency. It will tightly couple one class to another. It's not that new is bad, but you need to bear in mind the coupling that it creates. Make sure you're okay with it and that there's not a more appropriate place to choose which particular dependency your class will work with. Ask yourself, Do you need to specify the specific implementation you're going to use? Or maybe you could work with an abstraction instead and perhaps have it get passed in as a dependency. You may recall, I briefly mentioned the explicit dependencies principle in the previous module. This principle states that classes should explicitly require their dependencies through their constructor. This eliminates surprises since any developer trying to work with the type will immediately know what its dependencies are when they try to instantiate it. Think of any cooking recipe you've ever seen. The ingredients are always listed up front. How would you like it if you started to create a recipe and then thinking you had everything you needed, you are halfway through the recipe and it called for some ingredients that weren't in the list. That's exactly what having hidden dependencies in your classes is like. Now let's look at the effect abstractions have on dependencies in our software, specifically, how these dependencies vary between compile time and runtime. With no interfaces or abstractions as shown here, at compile time classes will reference the classes they directly instantiate and work with. And then at runtime, the call graph will mirror this dependency relationship. In this case, Class A references Class B, which references Class C. And then when we run this program, Class A will call Class B, and Class B will call Class C. With the addition of interfaces, however, the dependencies at compile time are inverted. Class A no longer depends on Class B, and Class B no longer depends on Class C. Instead, all of the classes depend on the two new interfaces. At runtime, the system behavior can remain the same with Class A calling into Class B calling into Class C. But now we've gone from tight to loose coupling. We've introduced several seams that can make testing easier, and we've made it much easier for us to swap out one implementation of Interface B or C with another in the future. If you'd like to learn more, I'd go into more depth on these architectural principles in the resources shown here. The dependency inversion principle, DIP, often goes hand-in-hand with a programming technique, dependency injection, which is sometimes referred to as DI. The explicit dependencies principle says you shouldn't create your own dependencies as this introduces tight coupling between them. Instead, you should depend on abstractions and request them from client software. Client code injects your class's dependencies ideally as constructor arguments, but sometimes using other means like properties or method arguments. The dependency injection technique is an implementation of the strategy design pattern, which you can learn more about in the Pluralsight Design Patterns Library course. I strongly recommend using constructor dependency injection wherever you can. It has several advantages over using a property or a method parameter to specify a dependency. First, it follows the explicit dependencies principle by ensuring client code is aware of what dependencies a given class has. Next, it ensures an instance of the class is always in an initialized state. A class that requires a property to be set before it can be used isn't nearly as intuitive to work with and will require more checks in client code to ensure its dependencies are set before it can be used. It's best if services that have dependencies are immutable so that once created, you don't need to worry about whether they still have what they need to work. Finally, constructor injection allows your code to leverage special factory types called IOC or DI containers. You configure these containers to map between abstractions and implementation types, and when your application runs, the container is used to instantiate types that have dependencies. These containers are sometimes called DI containers or simply services containers, and the container is able to resolve the dependencies of your classes at runtime providing a very flexible way to manage dependencies between your objects. If you're using ASP.NET Core, it has a built-in services collection as its container. You can use this directly, or you can replace it with a third-party container such as Autofac.

Demo: Applying DIP to ArdalisRating Sample
Now let's look at a demo showing how to apply the dependency inversion principle to the ArdalisRating sample application we've been working with throughout this course. The dependency inversion principle is key to reducing coupling, especially coupling to specific implementation details. We're going to focus on decoupling the RatingEngine from these details so that we'll have a more modular, maintainable, and testable system. Recall that the RatingEngine currently relies heavily on an instance of DefaultRatingContext for a lot of its functionality, including how it loads the policy data and how it deserializes it. Now we're going to apply the dependency inversion principle so that there isn't the direct dependency from RatingEngine to RatingContext and its associated concrete implementations for these features. One new feature we're being asked to support is logging to a file rather than console. We'll implement this along the way and test that it's working. We'll just go right down the list of methods that rate calls starting with Log. Currently, there's no way to change how RatingEngine does logging other than by changing the class itself because it directly calls Context.Log, which in turn is glued to the DefaultRatingContext by the new statement on line 9. Right now we can't easily test that any of the log output in the Rate method is working. The best we can do is run the application and visually inspect the console output, or perhaps pipe the output to a file and check that, which is an integration test, not a unit test, because it deals with the file system. The first step in applying DIP is to identify an interface using ISP and modify the code to depend on the interface rather than the concrete implementation. In this case, we already have an ILoggerInterface created in the previous module, so we can just use that. Following the explicit dependencies principle this time, we'll request an instance of ILogger from RatingEngine's constructor. Once we've done this, we can modify all the calls to Context.Log and replace them with _logger.Log. If we try to build, though, we'll see that Program.cs can no longer create the class. There are two ways we can fix this. First, we can use constructor chaining to provide a default implementation within the RatingEngine itself. To do that, we just create a new default constructor and have it chain to this with a new logger like so. This is a good technique to use when you have a large legacy system and you want to start following the explicit dependencies principle, but you don't want everything that currently creates the type to break. It's not ideal, though, because the dependency on the specific implementation is still there, and the other classes that use this default constructor are thus still tightly coupled to whatever concrete implementation is being used. The better approach if you can manage it is to eliminate the default constructor and pass in the dependencies wherever instantiation occurs, or just let your DI container do it for you if you're using one. In this case, we're only creating an instance of RatingEngine in exactly one place in our production code, the program entry point. So it makes sense to just specify the dependency there. Once we've done so, we also need to update any tests that create RatingEngine, which is a reminder that you should avoid duplicating your instantiation logic of your classes in your tests. So we can remove this default constructor, and with that gone, we'll take a look at Program.cs where we are now injecting a new ConsoleLogger when we create RatingEngine. The only other place that we need to perform this same type of change is inside of our test. Now in our RatingEngineRate test, we're going to create a FakeLogger and inject that into our RatingEngine. Now that we have access to this FakeLogger implementation, we can also start to write tests that verify that our logging is performing the way we expect. Let's look at such a test. This new test, RatingEngineRate, LogsStartingLoadingAndCompleting, takes an existing test and modifies it so that we can assert that the LoggedMessages are what we expect. Notice the three assertions at the end of this test. They verify that the LoggedMessages of our FakeLogger include a Starting rate message, a Loading policy message, and the Rating completed message. We can further assert the order of these if we wanted to, but just having these in place verifies that those messages were, in fact, logged as expected when this call to RatingEngineRate was made. We can look briefly at the implementation of FakeLogger. All it does is append any message that is passed to its Log method to a list of LoggedMessages that it exposes as a property. We can then access that list from our tests. Looking back at the test, note that this is still an integration test since it is writing an actual file. We'd like to be able to test logging without having to touch files since those aren't important to this test. It's also nice to split unit tests from integration tests since the former tend to run much faster and have fewer dependencies so they're generally more reliable. Right now the hardcoded dependency on Context is gluing the Rate method to file access. Let's address this next by applying DIP to it as well. Recall that we created the class FilePolicySource in module 1. This helped us achieve the single responsibility principle. Currently, the DefaultRatingContext is directly instantiating a FilePolicySource in order to implement its LoadPolicyFromFile method as you can see here. If we look at FilePolicySource, we see that it's a very simple one-line implementation. What we would like to do is apply the dependency inversion principle and also use the interface segregation principle to extract an interface for this particular class that we can then implement in multiple ways. The interface IPolicySource simply exposes the same method that the concrete FilePolicySource was implementing, but now it's an abstraction that we can use in multiple different ways in our system. Now we'd like to just compose this interface into IRatingContext, but, unfortunately, the methods don't match up. IRatingContext has LoadPolicyFromFile, not GetPolicyFromSource. So instead we look to DefaultRatingContext to see how FilePolicySource was used. LoadPolicyFromFile simply news-up FilePolicySource. We can replace that instance with an interface field and populate it from a constructor. First, we add the constructor along with the private read-only field for _policySource. And then we change the new FilePolicySource code to simply use our field. However, if we compile now, we get this error in RatingEngine where it tries to create DefaultRatingContext. To address this, we'll pass the new IPolicySource interface into RatingEngine as well, and move the creation of DefaultRatingContext into its constructor. This just moves the issue further up the call stack to Program.cs because now it needs to be able to provide an IPolicySource when it goes to create RatingEngine. That's just fine because that's where we want to specify the implementations our app will use is in the program's entry point. We fix the error here where we're creating RatingEngine at the start of the program by simply adding in the new FilePolicySource that we want it to use at runtime. Of course, we also need to make sure that FilePolicySource implements our IPolicySource interface. Once that's fixed, we're ready to address our Tests class. The current RatingEngineRate class uses real files, but it really doesn't need to for what it's testing. We can replace the IPolicySource with a fake one. Note that you could also use a mock object, but that's out of scope for this course. A FakePolicySource is just a class that lives in our test project and implements IPolicySource. It provides some way for Tests to verify that it is doing the work that we expect it to or to provide the expected input into our tests. In this case, our FakePolicySource just has a single property that represents the PolicyString that we want it to return. We'll set that property, and then when we call GetPolicyFromSource, it will simply return the contents of that property. Where before we are having to actually write out files to a policy.json file on our file system, now we're able to simply specify the JSON directly into the FakePolicySource, and then that is what is used by the engine eliminating any touching of the file system. These tests are now proper unit tests since they don't interact with the file system or any other dependencies outside of our code. Returning back to the RatingEngine's Rate method, the next use of Context is where it's going to use the serialization process. In this case, we're hard coding it to get it from a JSON string, and thus it's using the JSON serializer. However, we can use the same technique that we used with FilePolicySource to extract an interface for serialization and then inject it into our RatingEngine. Once we're done, the code looks like this. Now the RatingEngine has an IPolicySource and an IPolicySerializer being injected into it. These are also being injected into the DefaultRatingContext, which is still being used by the RatingEngine for now. Looking at the Rate method, we're able to use the _policySource directly to get the policyJson, and we're still using the context to get the policy from the JsonString. Since we have access to the policySerializer at this point, that's an easy fix to make right here. At the same time, we'll rename the variables so that they no longer refer to JSON as part of the nomenclature that we're using here. We don't care from this Rate method level what particular file format or encoding scheme is being used to serialize the data. We just care that we can use some serializer to get that policy from that string. The last call to RatingContext that we need to clean up and rate is this one, CreateRaterForPolicy. This is delegating to our RaterFactory that we created previously. Looking at this factory class, we see that it needs an IRatingContext. But what is it using? Just the Engine property. But why does it even need that? To create a RatingUpdater. So what it really needs is a RatingUpdater. So let's just give it that directly as a constructor parameter. We already have an IRatingUpdater interface, so we'll pass that into RaterFactory, and then we'll just make sure we create it further up the call stack. When we start injecting the RatingUpdater into the RaterFactory, it simplifies the Create method so that now we can just pass that RatingUpdater into any particular PolicyRater type that we instantiate. However, doing this brings to light an earlier design choice that wasn't ideal, namely the way ratings are updated. Our design as it stands now has RatingUpdater depending on RatingEngine, so it can update its rating property. But creating a RatingEngine requires a RaterFactory, which in turn now requires a RatingUpdater, so we have a circular dependency. We got around this previously by using property setters, but switching to using constructor arguments makes this problem more apparent. The simplest solution is to remove the dependency from Rater to engine by having Rater simply return the rating. This would eliminate the need for an IRatingUpdater entirely. This is a fairly sweeping change to the system, but now that things are loosely coupled and testable, it's a fairly low risk one. Essentially, we just need to change Rater so that instead of the Rate method being void, it returns a decimal rating. Currently, when no rate is set, the RatingEngine's Rate property remains its default of 0, so we can return 0 without changing the current behavior. If this weren't the case, we could return a rating result type that indicated success and then only set the property if the result were successful. With this change, Rater no longer requires a RatingUpdater. It simply returns back this decimal type. We can go through and modify each of the different raters so that instead of calling RatingUpdater, they just return back the appropriate decimal. Let's look at one as an example. The newly updated AutoPolicyRater returns back 0 if the policy is invalid. Otherwise, it will return back the correct 1000 or 900 rating value when it successfully rates a BMW with a certain deductible. In addition to making it easier to create our object dependency, this change also simplifies our tests since now that IRatingUpdater and FakeRatingUpdater are no longer required. We also took this opportunity to change the Logger inside of the base Rater class from being hardcoded to a new ConsoleLogger, and instead having it inject in an ILogger implementation through its constructor. At this point, when we go to create a RatingEngine, we just pass it in all of the dependencies that it's exposing. It's now following the explicit dependencies principle. It's telling us that it needs a logger. It needs some way to pull in data from a file or some other source of data. It needs some way to deserialize that data. In this case, we're going to use JSON. And it needs some way to produce the individual types of raters that it's going to use, which we're going to provide it a RaterFactory for. By the way, that RaterFactory, it also has a dependency on logger, and in this case, we're going to use the same logger for both of those things. Now the new feature that we wanted to implement at the start of this demo was the ability for us to log to a file. We can implement that now in this one place, and the change will impact the entire system instead of us having to touch multiple different points where we were instantiating a ConsoleLogger and change that behavior to use a FileLogger. Let's take a look at what that would be. A FileLogger is going to look very much like a ConsoleLogger except instead of just writing to the console, it's going to write out to a particular file. In this case, our requirements didn't specify that we needed to have any kind of configuration for what that log file should be, so we're just going to use log.txt for now. With this in place, we can change how the system outputs its log data by just going into Program.cs and changing the place where we instantiate the logger to use a FileLogger. Once we're done with that, we can run the application, and we see that the only output that's going to the console is coming from Program.cs, not from RatingEngine, which is now using a FileLogger. To view the log, we just need to go to the folder where the application ran. We can find this inside of our project in its bin, Debug, in this case netcoreapp2.2 folder where a new log.txt file has been created. And we can see the log output that is now going to this file instead of to the console. Notice that now that our system basically follows all the SOLID principles for the most part, there's still some refactoring we could do, we are able to follow the open close principle to add this new functionality. In order to add file logging instead of console logging, we didn't have to change any of our existing code. All we had to do was create a new class and inject that new class instead of the old behavior into our system. It's a very powerful technique that you can apply once you're following the SOLID principles that you've learned about in this course now.

Organizing and Extending Your SOLID Project
The dependency inversion principle is the fifth and last principle in the SOLID principles. It's one of the most important ones when it comes to ensuring your software stays loosely coupled, maintainable, and testable. It's required in order for your code to follow the explicit dependencies principle and to use the powerful dependency injection technique. Now I know some of you are wondering, Aren't there way too many files in this approach? It's true that following SOLID principles like SRP and ISP tend to result in smaller more focused classes and interfaces. As a result, there are more of these types, and typically that means more files. In the demos so far, I've intentionally been placing all of the files in the root of the project with the intention of organizing them at the end of the course. I have a top-secret technique I use for organizing large numbers of files. Use folders. That's right. If previously you had a couple of huge files, now you might have several folders with a few files in each one. Each file should be very specific in its task. So just by naming them appropriately, it should be pretty easy to find what you're looking for. There are several ways you can organize your files. The default that many developers use is by the kind of thing the file is. So you might put controllers in one folder and models in another, or you might have a folder for interfaces and another for services. However, another approach that works well, especially as applications grow, is to use feature folders. With feature folders, your top-level organization should be by feature, not by the kind of file. So an online store might have top-level folders for catalog, search, and cart, instead of models, controllers, views, and services. In any case, if you find that following SOLID is creating many files that you're having trouble managing, remember that folders are the simplest solution. Now let's take a look at how we can organize the ArdalisRating system, and while we're at it, let's go ahead and support a web front end to complement our existing console application. Now as a system like this grows in complexity, you'll almost certainly want to break it up into different projects. I would recommend following the clean architecture approach that I've talked about previously and which I have a sample for on my GitHub at github.com /ardalis. For now to keep this quick, I'm going to just add folders directly into the console application, and then I'll create an ASP.NET Core front end that relies on this console app. If we look at our project now, we see that it has about 20 or so different files in it, and we can organize these in some fashion based on where they are in the scope of our model. That is whether or not they're high level or low level, whether or not they're an abstraction or an implementation detail, and whether or not they're the entry point to our system, a UI concern, or if there's some part of the actual business rules that we're going to apply. We'll start by creating three folders, Core, Infrastructure, and UI. Core is where I want to place all my business logic that doesn't have any dependencies on other external concerns. Infrastructure is going to be where things that have dependencies on specific implementation details like the file system are going to live. And then UI is whatever my entry point into the system is. In this case, it's going to be Program.cs in our console application. Let's go ahead and start moving some files around to show where they belong in this new organization structure. When this is done, pretty much everything that was in the root of the project that we're using has been moved into one of these respective folders. Let's go through them one by one. Inside of the Core, we've moved our interfaces into an Interfaces folder. You might also name that Abstractions and, of course, as it grows, you might add additional folders or reorganize them so that they're with a particular feature that they go with. In this case, the whole ArdalisRating system basically only has one feature, which is to rate these policies, and so having them all in one place makes sense for now. Inside the model, we've grouped our Policy and PolicyType classes, and then all of the Raters along with their base rater type and the RaterFactory I've placed inside of a Raters folder so it's easy for me to find all those things. The RatingEngine, which is the most important part of this particular feature, is in the root of the Core folder, which, again, would probably be its own project if this were a real application. Looking at infrastructure now, we see that we have three subfolders, one for each of the different types of infrastructures that we're using. These are Loggers, PolicySources, and Serializers. Now normally I wouldn't create a folder for things that only have one element in them. It doesn't really do anything except add to some of the clutter inside your project system. In this case, I did so just to kind of show you how I would organize these as they continue to grow and you start to get additional implementations. And then, finally, our UI layer is just the entry point into our application, in this case Program.cs. Now looking at what's left in the root of this project, we see the things that we're no longer using, DefaultRatingContext and its IRatingContext interface, IRatingUpdater and RatingUpdater, which we just eliminated the need for. These can now just be deleted, and it's pretty obvious that this is the case because they're not in any of the other folders and nothing else is using them. Now it's possible in this example demo system that DefaultRatingContext or IRatingContext is being used by other applications. If that's the case, we would simply move these types into a shared DLL or NuGet package rather than deleting them completely. But we don't need them here, so they can go. Likewise, inside our Tests, we had a FakeRatingUpdater. It can go as well. With that done, we're now finished with organizing the ArdalisRating console application. If we want to add a web front end, we just add a new ASP.NET Core web project and wire it up to use the same interfaces and types that we're using from the console program. Now I spent a few moments creating this new ASP.NET Core Web API project called WebRating. I've given it a single RateController class. And in here, you can see it has one Rate method that takes in a post with a string containing a policy. It uses a _policySource to grab that string, which will then be used by the RatingEngine. The RatingEngine, as you recall, simply sets its Rating property when it executes, and so this controller action can just return that Rating property in order for it to be all wired up and working as expected. I've added something called Swagger to this API so that when we run it, we can interact with the API directly in the browser. This is the UI generated by Swagger. You see that it has our Rate method here. We can expand this and get some details about this particular API endpoint. We can also try it out. We can specify here that we have an auto policy for a BMW that we would like to rate. Scroll down a bit, click Execute, and we see in our results that we get a 1000 as the result, which is what we expect. This is the same result we would get from the console program if we were to run the same code. You can explore this sample in the associated GitHub project for this course. I don't have time to review it in this demo, but you can see how easy it is now that we have broken apart our application to make it so that we can reuse the core business logic of the app with different front end implementations.

Key Takeaways and Summary
Your key takeaways for the dependency inversion principle are, first, to make sure that your higher-level classes depend on abstractions, not implementation details. Then be sure that these abstractions don't leak details. They shouldn't care about how they're implemented. Be sure to write your classes so they are explicit about what they need, and clients should inject these classes' dependencies when they create them, perhaps using a container to help with this. Finally, use folders in an appropriately structured solution to leverage dependency inversion and produce code that's loosely coupled and easy to maintain and test. Now let's review the principles one last time and see how they interrelate. Also, just a reminder, you'll find the samples for this course on GitHub at this location. Here are the five SOLID principles arranged a bit differently from how you've seen them thus far. At the top, single responsibility and interface segregation promote small, cohesive types. Once you're using small, cohesive types, for most of your application's functionality, it becomes easy to follow the open close principle because now new functionality can be added by adding new classes as we saw in some of the demos in this course. Another benefit of using smaller, fit-for-purpose interfaces is that they're much easier to fully implement and thus to follow the Liskov substitution principle. Of course, when you're following OCP, one important way to change behavior is by passing in dependencies, which requires following the dependency inversion principle. And, finally, it's important to remember that the interfaces the system uses should not depend on details, but rather the dependency inversion principle requires that details depend on these interfaces. Thanks for watching. I've found the SOLID principles to be invaluable in how I write more maintainable software applications, and I've helped countless developers and teams reduce technical debt and write cleaner code by using these principles. If you'd like to learn more, find me online at ardalis.com or my podcast, weeklydevtips. Until next time, keep improving.

Course author
Author: Steve Smith	
Steve Smith
Steve Smith (@ardalis) is an entrepreneur and software developer with a passion for building quality software as effectively as possible. He provides mentoring and training workshops for teams with...

Course info
Level
Beginner
Rating
4.7668 stars with 253 raters(253)
My rating
null stars

Duration
2h 8m
Released
2 Apr 2019
Share course
Features
Â·
Authors
Â·
Mobile & offline apps
Â·
Blog
Â·
Help center
Â·
How-to videos
Â·
Referral program
Â·
Terms of use
Â·
Privacy policy
Send feedback
Get support